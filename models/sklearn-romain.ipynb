{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.metrics import f1_score, classification_report\n",
    "\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "stopwords = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "kaggle_ds = pd.read_csv(\"data/kaggle_dataset.csv\")\n",
    "mac_ds = pd.read_csv(\"data/merged_and_cleaned.csv\")\n",
    "mac_rm_ds = pd.read_csv(\"data/merged_and_cleaned_rm.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model (with base dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Emotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>i didnt feel humiliated</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>i can go from feeling so hopeless to so damned...</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>im grabbing a minute to post i feel greedy wrong</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>i am ever feeling nostalgic about the fireplac...</td>\n",
       "      <td>love</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>i am feeling grouchy</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21454</th>\n",
       "      <td>Melissa stared at her friend in dism</td>\n",
       "      <td>fear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21455</th>\n",
       "      <td>Successive state elections have seen the gover...</td>\n",
       "      <td>fear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21456</th>\n",
       "      <td>Vincent was irritated but not dismay</td>\n",
       "      <td>fear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21457</th>\n",
       "      <td>Kendall-Hume turned back to face the dismayed ...</td>\n",
       "      <td>fear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21458</th>\n",
       "      <td>I am dismayed , but not surpris</td>\n",
       "      <td>fear</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>21459 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    Text  Emotion\n",
       "0                                i didnt feel humiliated  sadness\n",
       "1      i can go from feeling so hopeless to so damned...  sadness\n",
       "2       im grabbing a minute to post i feel greedy wrong    anger\n",
       "3      i am ever feeling nostalgic about the fireplac...     love\n",
       "4                                   i am feeling grouchy    anger\n",
       "...                                                  ...      ...\n",
       "21454               Melissa stared at her friend in dism     fear\n",
       "21455  Successive state elections have seen the gover...     fear\n",
       "21456               Vincent was irritated but not dismay     fear\n",
       "21457  Kendall-Hume turned back to face the dismayed ...     fear\n",
       "21458                    I am dismayed , but not surpris     fear\n",
       "\n",
       "[21459 rows x 2 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kaggle_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = kaggle_ds[\"Text\"], kaggle_ds[\"Emotion\"]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tweet_tokenizer(text):\n",
    "  text = re.sub(r'http\\S+', '', text)\n",
    "  tt = TweetTokenizer(reduce_len=True, strip_handles=True)\n",
    "  return tt.tokenize(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Pipeline([\n",
    "  ('count', CountVectorizer(stop_words=stopwords, tokenizer=tweet_tokenizer)),\n",
    "  # ('tfid', TfidfVectorizer(stop_words=stopwords)),\n",
    "  ('nb', MultinomialNB())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rom1/opt/anaconda3/envs/datascience/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:396: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['doe', 'ha', 'wa'] not in stop_words.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('count',\n",
       "                 CountVectorizer(stop_words=['i', 'me', 'my', 'myself', 'we',\n",
       "                                             'our', 'ours', 'ourselves', 'you',\n",
       "                                             \"you're\", \"you've\", \"you'll\",\n",
       "                                             \"you'd\", 'your', 'yours',\n",
       "                                             'yourself', 'yourselves', 'he',\n",
       "                                             'him', 'his', 'himself', 'she',\n",
       "                                             \"she's\", 'her', 'hers', 'herself',\n",
       "                                             'it', \"it's\", 'its', 'itself', ...],\n",
       "                                 tokenizer=<__main__.LemmaTokenizer object at 0x1616c9f30>)),\n",
       "                ('nb', MultinomialNB())])"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1 score: 0.7610864911639719\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "print(f\"f1 score: {f1_score(y_test, y_pred, average='weighted')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       anger       0.91      0.64      0.76       764\n",
      "        fear       0.84      0.62      0.71       661\n",
      "       happy       0.75      0.94      0.83      1715\n",
      "        love       0.92      0.34      0.50       396\n",
      "     sadness       0.76      0.94      0.84      1625\n",
      "    surprise       0.86      0.12      0.21       204\n",
      "\n",
      "    accuracy                           0.78      5365\n",
      "   macro avg       0.84      0.60      0.64      5365\n",
      "weighted avg       0.80      0.78      0.76      5365\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model (with merged datasets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge and colums change"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Emotion</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sadness</td>\n",
       "      <td>@tiffanylue i know  i was listenin to bad habi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sadness</td>\n",
       "      <td>Layin n bed with a headache  ughhhh...waitin o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sadness</td>\n",
       "      <td>Funeral ceremony...gloomy friday...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>happiness</td>\n",
       "      <td>wants to hang out with friends SOON!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>fear</td>\n",
       "      <td>Re-pinging @ghostridah14: why didn't you go to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51111</th>\n",
       "      <td>fear</td>\n",
       "      <td>Melissa stared at her friend in dism</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51112</th>\n",
       "      <td>fear</td>\n",
       "      <td>Successive state elections have seen the gover...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51113</th>\n",
       "      <td>fear</td>\n",
       "      <td>Vincent was irritated but not dismay</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51114</th>\n",
       "      <td>fear</td>\n",
       "      <td>Kendall-Hume turned back to face the dismayed ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51115</th>\n",
       "      <td>fear</td>\n",
       "      <td>I am dismayed , but not surpris</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>51116 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Emotion                                               Text\n",
       "0        sadness  @tiffanylue i know  i was listenin to bad habi...\n",
       "1        sadness  Layin n bed with a headache  ughhhh...waitin o...\n",
       "2        sadness                Funeral ceremony...gloomy friday...\n",
       "3      happiness               wants to hang out with friends SOON!\n",
       "4           fear  Re-pinging @ghostridah14: why didn't you go to...\n",
       "...          ...                                                ...\n",
       "51111       fear               Melissa stared at her friend in dism\n",
       "51112       fear  Successive state elections have seen the gover...\n",
       "51113       fear               Vincent was irritated but not dismay\n",
       "51114       fear  Kendall-Hume turned back to face the dismayed ...\n",
       "51115       fear                    I am dismayed , but not surpris\n",
       "\n",
       "[51116 rows x 2 columns]"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mac_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = mac_ds[\"Text\"], mac_ds[\"Emotion\"]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer \n",
    "class LemmaTokenizer(object):\n",
    "    def __init__(self):\n",
    "        self.wnl = WordNetLemmatizer()\n",
    "    def __call__(self, articles):\n",
    "        return [self.wnl.lemmatize(t) for t in tweet_tokenizer(articles)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Pipeline([\n",
    "  ('count', CountVectorizer(stop_words=stopwords, tokenizer=LemmaTokenizer())),\n",
    "  # ('tfid', TfidfVectorizer(stop_words=stopwords, tokenizer=tweet_tokenizer)),\n",
    "  ('nb', MultinomialNB())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rom1/opt/anaconda3/envs/datascience/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:396: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['doe', 'ha', 'wa'] not in stop_words.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('count',\n",
       "                 CountVectorizer(stop_words=['i', 'me', 'my', 'myself', 'we',\n",
       "                                             'our', 'ours', 'ourselves', 'you',\n",
       "                                             \"you're\", \"you've\", \"you'll\",\n",
       "                                             \"you'd\", 'your', 'yours',\n",
       "                                             'yourself', 'yourselves', 'he',\n",
       "                                             'him', 'his', 'himself', 'she',\n",
       "                                             \"she's\", 'her', 'hers', 'herself',\n",
       "                                             'it', \"it's\", 'its', 'itself', ...],\n",
       "                                 tokenizer=<__main__.LemmaTokenizer object at 0x1639df940>)),\n",
       "                ('nb', MultinomialNB())])"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       anger       0.88      0.36      0.51      1112\n",
      "        fear       0.46      0.58      0.51      2805\n",
      "   happiness       0.44      0.66      0.53      1882\n",
      "       happy       0.69      0.90      0.78      1755\n",
      "        love       0.61      0.22      0.33      1350\n",
      "     sadness       0.58      0.60      0.59      3077\n",
      "    surprise       0.59      0.03      0.05       798\n",
      "\n",
      "    accuracy                           0.55     12779\n",
      "   macro avg       0.61      0.48      0.47     12779\n",
      "weighted avg       0.58      0.55      0.52     12779\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge and colums removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = mac_rm_ds[\"Text\"], mac_rm_ds[\"Emotion\"]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Pipeline([\n",
    "  ('count', CountVectorizer(stop_words=stopwords, tokenizer=LemmaTokenizer())),\n",
    "  # ('tfid', TfidfVectorizer(stop_words=stopwords, tokenizer=tweet_tokenizer)),\n",
    "  ('nb', MultinomialNB())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rom1/opt/anaconda3/envs/datascience/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:396: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['doe', 'ha', 'wa'] not in stop_words.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('count',\n",
       "                 CountVectorizer(stop_words=['i', 'me', 'my', 'myself', 'we',\n",
       "                                             'our', 'ours', 'ourselves', 'you',\n",
       "                                             \"you're\", \"you've\", \"you'll\",\n",
       "                                             \"you'd\", 'your', 'yours',\n",
       "                                             'yourself', 'yourselves', 'he',\n",
       "                                             'him', 'his', 'himself', 'she',\n",
       "                                             \"she's\", 'her', 'hers', 'herself',\n",
       "                                             'it', \"it's\", 'its', 'itself', ...],\n",
       "                                 tokenizer=<__main__.LemmaTokenizer object at 0x16c50d3c0>)),\n",
       "                ('nb', MultinomialNB())])"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       anger       0.87      0.50      0.64       769\n",
      "        fear       0.87      0.51      0.64       621\n",
      "   happiness       0.48      0.65      0.55      1326\n",
      "       happy       0.70      0.90      0.79      1792\n",
      "        love       0.57      0.33      0.42      1375\n",
      "     sadness       0.63      0.82      0.72      2842\n",
      "    surprise       0.56      0.09      0.15       768\n",
      "\n",
      "    accuracy                           0.63      9493\n",
      "   macro avg       0.67      0.54      0.56      9493\n",
      "weighted avg       0.64      0.63      0.61      9493\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b4f38127354bbbf11134e8c14cc17daac7b35e8faaf836cc12d7980bb5480b10"
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 ('datascience')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
